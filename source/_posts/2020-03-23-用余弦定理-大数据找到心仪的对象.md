---
title: 用余弦定理+大数据找到心仪的对象
categories:
  - 技术

date: 2020-03-23 22:16:11
---

![cosin](https://github.com/user-attachments/assets/4b31696c-e3ec-4625-9eb7-bf760d32c4a8)

## [](#前言 "前言")前言

余弦定理和找对象似乎是两件八杆子打不着的事，但是它们却有着类似于余弦定理和 Google 的新闻自动分类一样的紧密联系。具体来说，找对象也可以和做 Google 的新闻自动分类一样，找到最契合的另一半。

<!-- more -->

## [](#原理 "原理")原理

找对象之前，先来看看文章自动分类的原理，我们做文章自动分类时，第一步是从分词入手

### [](#第一步，分词 "第一步，分词")第一步，分词

这里使用了一个 Node.js 比较成熟的分词库，底层算法是基于 c++做的实现，性能不错。

参见 [/index.js#L88](https://github.com/tkvern/nodejs-text-similarity/blob/master/index.js#L88)

```typescript
/**
 * 简单分词
 * @param {String} text 文本
 * @returns {Array}
 */
segment(text) {
  if (!text) return []
  return nodejieba.cut(text)
}
```

### [](#第二步，-列出所有词 "第二步， 列出所有词")第二步， 列出所有词

分词之后我们将得到所有的词

参见 [/index.js#L11](https://github.com/tkvern/nodejs-text-similarity/blob/master/index.js#L11)

```typescript
/**
 * 文本相似度查询
 * @param {String} textA 文本A
 * @param {String} textB 文本B
 */
constructor(textA, textB) {
  textA = "" + textA
  textB = "" + textB
  this.segmentWordsA = this.segment(textA)
  this.segmentWordsB = this.segment(textB)
}
```

### [](#第三步，统计词频率 "第三步，统计词频率")第三步，统计词频率

当我们拿到所有词的数组后，还需要进行词频统计，`EXCLUDE_WORDS_ARRAY`这个是我们排出的一些语气助词。

参见 [/index.js#L43](https://github.com/tkvern/nodejs-text-similarity/blob/master/index.js#L43)

```typescript
/**
 * 分析两段文本
 */
analyse() {
  // 分析A片段
  this.segmentWordsA.forEach(element => {
    if (!this.EXCLUDE_WORDS_ARRAY.includes(element)) {
      if (!this.distributionWordsArray.hasOwnProperty(element)) {
        this.distributionWordsArray[element] = [1, 0]
      } else {
        this.distributionWordsArray[element][0] += 1
      }
    }
  })

  // 分析B片段
  this.segmentWordsB.forEach(element => {
    if (!this.EXCLUDE_WORDS_ARRAY.includes(element)) {
      if (!this.distributionWordsArray.hasOwnProperty(element)) {
        this.distributionWordsArray[element] = [0, 1]
      } else {
        this.distributionWordsArray[element][1] += 1
      }
    }
  })
}
```

### [](#第四步，根据词频向量计算相似程度 "第四步，根据词频向量计算相似程度")第四步，根据词频向量计算相似程度

```bash
句子 A： "太阳刚升起夕阳已落下"
句子 B： "我在马路边夕阳已落下"
```

通过计算，我们会得到这样一个词频数组

![向量](https://github.com/user-attachments/assets/0172e513-6f37-452a-8352-e54fc3d8f732)

结合余弦定理:

![夹角](https://github.com/user-attachments/assets/50907259-b61c-4f48-a470-75f1bde310a5)

对于 n 维向量的计算如下:

![n维计算](https://github.com/user-attachments/assets/90b05896-9078-47fe-9b3b-ffa8aa3950f5)

而计算出来的余弦值越接近 1，则表明夹角越接近 0 度，也就是两个向量越相似。

参见[/index.js#71]((https://github.com/tkvern/nodejs-text-similarity/blob/master/index.js#L43)

```typescript
/**
 * 处理相似度
 * @returns {Number}
 */
similarity() {
  let [sum, sumWordsA, sumWordsB] = [0, 0, 0]
  for (const element in this.distributionWordsArray) {
    const wordsA = this.distributionWordsArray[element][0]
    const wordsB = this.distributionWordsArray[element][1]
    sum += (wordsA * wordsB)
    sumWordsA += Math.pow(wordsA, 2)
    sumWordsB += Math.pow(wordsB, 2)
  }
  return sum / Math.sqrt(sumWordsA * sumWordsB)
}
```

## [](#找对象 "找对象")找对象

和做文章自动分类一样

### [](#第一步，基本信息、个性、兴趣爱好分析 "第一步，基本信息、个性、兴趣爱好分析")第一步，基本信息、个性、兴趣爱好分析

和分词原理类似，我们要将每个人的物理数据数字化，并按照不同的维度拆分

### [](#第二步，列出所有数字化后的数据 "第二步，列出所有数字化后的数据")第二步，列出所有数字化后的数据

分析之后，我们将得到数字化的人物画像。

### [](#第三步，参数统计 "第三步，参数统计")第三步，参数统计

对数字化后的每一项数据，进行统计

### [](#第四步，计算相似程度 "第四步，计算相似程度")第四步，计算相似程度

这里用到的计算方法和词频统计一样，而拓展一些的地方是，可以给某些参数增加权重。

这样就可以结合你的个人状况，找到最适合你的对象了。

## [](#大数据 "大数据")大数据

你应该已经注意到了，我们做文章自动分类的前提，是有足够多的文章数据

所以，用余弦定理+大数据找到心仪的对象，也需要有足够多的数字化数据。

而一切的前提，是要有足够多的对象数据，所以要先挖掘下数据吧。

![happy](https://github.com/user-attachments/assets/3f2bd6f7-74a7-4610-a1a1-46570e6633e3)

## [](#Plan "Plan")Plan

我有个帮你找对象的计划，如果你有找对象的需求，可以提交到我的系统里面来哦～

## [](#项目地址 "项目地址")项目地址

文中代码仓库请访问 [https://github.com/tkvern/nodejs-text-similarity](https://github.com/tkvern/nodejs-text-similarity)
